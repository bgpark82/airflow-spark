ë§ì”€í•˜ì‹  ê²ƒì²˜ëŸ¼, Docker Hubì—ì„œ ì œê³µë˜ë˜ **Bitnamiì˜ Spark ì´ë¯¸ì§€**(`bitnami/spark`)ëŠ” ê³µì‹ì ìœ¼ë¡œ ì„œë¹„ìŠ¤ê°€ ì¤‘ë‹¨ë˜ê±°ë‚˜ ì§€ì›ì´ ë¶ˆì•ˆì •í•´ì§€ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.

ê°€ì¥ ì¢‹ì€ ëŒ€ì•ˆì€ **ê³µì‹ Apache Spark ì´ë¯¸ì§€**ë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜, ê³µì‹ ì´ë¯¸ì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬(PySpark, Jupyter ë“±)ë¥¼ ì¶”ê°€í•˜ì—¬ ì§ì ‘ ë¹Œë“œí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

## ğŸ¥‡ ìµœê³ ì˜ ëŒ€ì•ˆ: Apache Spark ê³µì‹ ì´ë¯¸ì§€

Spark ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ê°€ì¥ ê¶Œì¥í•˜ëŠ” ëŒ€ì•ˆì€ **Apache Software Foundation**ì—ì„œ ê´€ë¦¬í•˜ëŠ” ê³µì‹ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

| ì´ë¯¸ì§€ ì´ë¦„ | ì„¤ëª… |
| :--- | :--- |
| **`apache/spark`** | Apache Spark í”„ë¡œì íŠ¸ì—ì„œ ì œê³µí•˜ëŠ” **ê³µì‹ Docker ì´ë¯¸ì§€**ì…ë‹ˆë‹¤. Spark Master, Worker, History Server ë“±ì„ êµ¬ì„±í•˜ëŠ” ë° ê°€ì¥ ì•ˆì •ì ì¸ ê¸°ë°˜ì…ë‹ˆë‹¤. |

### âœ… ê³µì‹ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•œ `docker-compose.yaml` ì˜ˆì‹œ

ì´ì „ ì§ˆë¬¸ì—ì„œ ì‚¬ìš©í•˜ì…¨ë˜ Bitnami ì´ë¯¸ì§€ ëŒ€ì‹  ê³µì‹ `apache/spark` ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ Spark í´ëŸ¬ìŠ¤í„°ë¥¼ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```yaml
version: '3.8'
services:
  spark-master:
    image: apache/spark:3.5.7  # ì›í•˜ëŠ” Spark ë²„ì „ìœ¼ë¡œ ë³€ê²½ (ìµœì‹  ì•ˆì • ë²„ì „ ê¶Œì¥)
    container_name: spark-master
    hostname: spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
    ports:
      - '8080:8080' # Master Web UI
      - '7077:7077' # Master í†µì‹ 
  
  spark-worker:
    image: apache/spark:3.5.7  # Masterì™€ ë™ì¼í•œ ë²„ì „ ì‚¬ìš©
    container_name: spark-worker-1
    hostname: spark-worker-1
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2g
    ports:
      - '8081:8081' # Worker Web UI (í•„ìš”í•˜ë‹¤ë©´)

# ... (JupyterLab ì„œë¹„ìŠ¤ëŠ” 3ë‹¨ê³„ì˜ Dockerfileì„ ì‚¬ìš©í•˜ì—¬ ë³„ë„ë¡œ ë¹Œë“œí•˜ì—¬ ì—°ê²°)
```

### ğŸ¥ˆ ê¸°íƒ€ ëŒ€ì•ˆ ë° PySpark í™˜ê²½ êµ¬ì„±

ê³µì‹ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ë©´ì„œ PySparkë‚˜ JupyterLabì„ í•¨ê»˜ ì‚¬ìš©í•˜ë ¤ë©´ ë‹¤ìŒ ë°©ë²• ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.

1.  **ê³µì‹ ì´ë¯¸ì§€ + PySpark (ê°€ì¥ ì‰¬ìš´ ë°©ë²•):**

    * ê³µì‹ ì´ë¯¸ì§€ì—ëŠ” Python 3 í™˜ê²½ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. PySpark ì…¸ì„ ì‹¤í–‰í•˜ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
      ```bash
      docker run -it --rm apache/spark:3.5.7 /opt/spark/bin/pyspark
      ```

2.  **ì§ì ‘ ë¹Œë“œ (JupyterLab í†µí•©):**

    * ì´ì „ ë‹µë³€ì—ì„œ ì„¤ëª…í–ˆë“¯ì´, `apache/spark` ì´ë¯¸ì§€ë¥¼ `FROM`ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ **Dockerfileì„ ì§ì ‘ ì‘ì„±**í•˜ê³ , ì—¬ê¸°ì— `JupyterLab`, `pyspark` ë“±ì˜ Python íŒ¨í‚¤ì§€ë¥¼ `pip install`ë¡œ ì¶”ê°€í•˜ì—¬ ìì‹ ë§Œì˜ ì´ë¯¸ì§€ë¥¼ ë¹Œë“œí•˜ëŠ” ê²ƒì´ ê°€ì¥ ì¼ë°˜ì ì´ê³  ìœ ì—°í•œ ë°©ë²•ì…ë‹ˆë‹¤.

ì´ ë™ì˜ìƒì€ Dockerë¥¼ ì‚¬ìš©í•˜ì—¬ Kubernetesì— Apache Spark ì‘ì—…ì„ ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì„ ë‹¨ê³„ë³„ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤. [Run Apache Spark on Kubernetes with Docker | Step-by-Step Tutorial](https://www.youtube.com/watch?v=P5UKwFYtvj0&vl=ko)

http://googleusercontent.com/youtube_content/0
